---
title: Latest 20 Papers - October 31, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## AND:multimodal LLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DiagramEval: Evaluating LLM-Generated Diagrams via Graphs](http://arxiv.org/abs/2510.25761v1)** | 2025-10-29 |  |
| **[RoboOmni: Proactive Robot Manipulation in Omni-modal Context](http://arxiv.org/abs/2510.23763v2)** | 2025-10-29 |  |
| **[A Critical Study of Automatic Evaluation in Sign Language Translation](http://arxiv.org/abs/2510.25434v1)** | 2025-10-29 | <details><summary>Submi...</summary><p>Submitted to the LREC 2026 conference</p></details> |
| **[CGM-Led Multimodal Tracking with Chatbot Support: An Autoethnography in Sub-Health](http://arxiv.org/abs/2510.25381v1)** | 2025-10-29 | <details><summary>confe...</summary><p>conference paper, prepint</p></details> |
| **[Open3D-VQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space](http://arxiv.org/abs/2503.11094v3)** | 2025-10-29 |  |
| **[WEST: LLM based Speech Toolkit for Speech Understanding, Generation, and Interaction](http://arxiv.org/abs/2509.19902v2)** | 2025-10-29 |  |
| **[TraveLLM: Could you plan my new public transit route in face of a network disruption?](http://arxiv.org/abs/2407.14926v2)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted to ITSC 2025</p></details> |
| **[MMM-Fact: A Multimodal, Multi-Domain Fact-Checking Dataset with Multi-Level Retrieval Difficulty](http://arxiv.org/abs/2510.25120v1)** | 2025-10-29 | <details><summary>Datas...</summary><p>Dataset link: https://huggingface.co/datasets/Wenyan0110/MMM-Fact</p></details> |
| **[SeeingEye: Agentic Information Flow Unlocks Multimodal Reasoning In Text-only LLMs](http://arxiv.org/abs/2510.25092v1)** | 2025-10-29 |  |
| **[H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts](http://arxiv.org/abs/2510.25091v1)** | 2025-10-29 |  |
| **[TowerVision: Understanding and Improving Multilinguality in Vision-Language Models](http://arxiv.org/abs/2510.21849v2)** | 2025-10-28 | <details><summary>15 pa...</summary><p>15 pages, 7 figures, submitted to arXiv October 2025. All models, datasets, and training code will be released at https://huggingface.co/collections/utter-project/towervision</p></details> |
| **[Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives](http://arxiv.org/abs/2510.24551v1)** | 2025-10-28 |  |
| **[OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions](http://arxiv.org/abs/2505.21724v2)** | 2025-10-28 | 25 pages, 9 figures |
| **[Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs](http://arxiv.org/abs/2505.11842v3)** | 2025-10-28 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025 Dataset and Benchmark Track, Project page: https://liuxuannan.github.io/Video-SafetyBench.github.io/</p></details> |
| **[What do vision-language models see in the context? Investigating multimodal in-context learning](http://arxiv.org/abs/2510.24331v1)** | 2025-10-28 |  |
| **[NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables](http://arxiv.org/abs/2504.06560v4)** | 2025-10-28 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs](http://arxiv.org/abs/2510.24214v1)** | 2025-10-28 | NeurIPS 2025 |
| **[MGA: Memory-Driven GUI Agent for Observation-Centric Interaction](http://arxiv.org/abs/2510.24168v1)** | 2025-10-28 | Submitted to WWW2025 |
| **[PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning](http://arxiv.org/abs/2507.01271v4)** | 2025-10-28 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2025 Workshop: Evaluating the Evolving LLM Lifecycle</p></details> |
| **[GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training](http://arxiv.org/abs/2509.24494v2)** | 2025-10-28 | Under review |

## AND:multimodal survey
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](http://arxiv.org/abs/2510.25760v1)** | 2025-10-29 |  |
| **[Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models](http://arxiv.org/abs/2510.05034v5)** | 2025-10-28 | Version v1.1 |
| **[Toward Socially-Aware LLMs: A Survey of Multimodal Approaches to Human Behavior Understanding](http://arxiv.org/abs/2510.23947v1)** | 2025-10-28 |  |
| **[LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell Biology](http://arxiv.org/abs/2510.07793v2)** | 2025-10-27 | <details><summary>34 pa...</summary><p>34 pages, 5 figures, 7 tables</p></details> |
| **[Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges](http://arxiv.org/abs/2510.22964v1)** | 2025-10-27 |  |
| **[A Survey of Long-Document Retrieval in the PLM and LLM Era](http://arxiv.org/abs/2509.07759v2)** | 2025-10-25 | 32 pages, 6 figures |
| **[Bridging the Perceptual-Statistical Gap in Dysarthria Assessment: Why Machine Learning Still Falls Short](http://arxiv.org/abs/2510.22237v1)** | 2025-10-25 |  |
| **[Deep Literature Survey Automation with an Iterative Workflow](http://arxiv.org/abs/2510.21900v1)** | 2025-10-24 | Preprint version |
| **[Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques](http://arxiv.org/abs/2410.18972v2)** | 2025-10-24 |  |
| **[A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation](http://arxiv.org/abs/2510.19755v2)** | 2025-10-23 | 22 pages,2 figures |
| **[LLM-empowered knowledge graph construction: A survey](http://arxiv.org/abs/2510.20345v1)** | 2025-10-23 |  |
| **[Review of Tools for Zero-Code LLM Based Application Development](http://arxiv.org/abs/2510.19747v1)** | 2025-10-22 | <details><summary>Accep...</summary><p>Accepted in 6th World Conference on Artificial Intelligence: Advances and Applications (WCAIAA 2025)</p></details> |
| **[Machine Olfaction and Embedded AI Are Shaping the New Global Sensing Industry](http://arxiv.org/abs/2510.19660v1)** | 2025-10-22 | <details><summary>23 pa...</summary><p>23 pages, 116 citations, combination tech review/industry roadmap/white paper on the rise of machine olfaction as an essential AI modality</p></details> |
| **[A Survey of Process Reward Models: From Outcome Signals to Process Supervisions for Large Language Models](http://arxiv.org/abs/2510.08049v2)** | 2025-10-21 |  |
| **[DeepSeek-Inspired Exploration of RL-based LLMs and Synergy with Wireless Networks: A Survey](http://arxiv.org/abs/2503.09956v4)** | 2025-10-20 | 45 pages, 12 figures |
| **[From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery](http://arxiv.org/abs/2508.14111v2)** | 2025-10-20 |  |
| **[From Multimodal Perception to Strategic Reasoning: A Survey on AI-Generated Game Commentary](http://arxiv.org/abs/2506.17294v2)** | 2025-10-18 |  |
| **[A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers](http://arxiv.org/abs/2508.21148v2)** | 2025-10-18 |  |
| **[Methods and Trends in Detecting AI-Generated Images: A Comprehensive Review](http://arxiv.org/abs/2502.15176v2)** | 2025-10-17 | <details><summary>34 pa...</summary><p>34 pages, 4 Figures, 10 Tables</p></details> |
| **[Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding](http://arxiv.org/abs/2510.15253v1)** | 2025-10-17 |  |

## AND:MLLM post training
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](http://arxiv.org/abs/2510.25760v1)** | 2025-10-29 |  |
| **[SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing](http://arxiv.org/abs/2510.24820v1)** | 2025-10-28 |  |
| **[First SFT, Second RL, Third UPT: Continual Improving Multi-Modal LLM Reasoning via Unsupervised Post-Training](http://arxiv.org/abs/2505.22453v2)** | 2025-10-27 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[LUQ: Layerwise Ultra-Low Bit Quantization for Multimodal Large Language Models](http://arxiv.org/abs/2509.23729v2)** | 2025-10-26 |  |
| **[Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback](http://arxiv.org/abs/2510.16888v2)** | 2025-10-21 |  |
| **[Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](http://arxiv.org/abs/2508.05612v3)** | 2025-10-21 | <details><summary>Proje...</summary><p>Project page at: https://xenozlh.github.io/Shuffle-R1/</p></details> |
| **[GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image](http://arxiv.org/abs/2510.17157v1)** | 2025-10-20 |  |
| **[Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence](http://arxiv.org/abs/2510.16555v1)** | 2025-10-18 |  |
| **[REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting](http://arxiv.org/abs/2510.16410v1)** | 2025-10-18 |  |
| **[RL makes MLLMs see better than SFT](http://arxiv.org/abs/2510.16333v1)** | 2025-10-18 |  |
| **[Detect Anything via Next Point Prediction](http://arxiv.org/abs/2510.12798v1)** | 2025-10-14 | <details><summary>homep...</summary><p>homepage: https://rex-omni.github.io/</p></details> |
| **[MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization](http://arxiv.org/abs/2510.08540v2)** | 2025-10-11 |  |
| **[RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models](http://arxiv.org/abs/2506.18369v4)** | 2025-10-10 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025</p></details> |
| **[Play to Generalize: Learning to Reason Through Game Play](http://arxiv.org/abs/2506.08011v4)** | 2025-10-09 | <details><summary>Proje...</summary><p>Project Page: https://yunfeixie233.github.io/ViGaL/</p></details> |
| **[PiCo: Jailbreaking Multimodal Large Language Models via Pictorial Code Contextualization](http://arxiv.org/abs/2504.01444v4)** | 2025-10-09 | <details><summary>Accep...</summary><p>Accepted to IEEE International Conference on Multimedia and Expo (ICME) 2025</p></details> |
| **[ReLoop: "Seeing Twice and Thinking Backwards" via Closed-loop Training to Mitigate Hallucinations in Multimodal understanding](http://arxiv.org/abs/2507.04943v2)** | 2025-09-30 | <details><summary>Accep...</summary><p>Accepted by conference EMNLP2025</p></details> |
| **[LFTR: Learning-Free Token Reduction for Multimodal Large Language Models](http://arxiv.org/abs/2501.17391v3)** | 2025-09-30 |  |
| **[Visual Jigsaw Post-Training Improves MLLMs](http://arxiv.org/abs/2509.25190v1)** | 2025-09-29 |  |
| **[Scaling Synthetic Task Generation for Agents via Exploration](http://arxiv.org/abs/2509.25047v1)** | 2025-09-29 |  |
| **[FreeRet: MLLMs as Training-Free Retrievers](http://arxiv.org/abs/2509.24621v1)** | 2025-09-29 |  |

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](http://arxiv.org/abs/2510.25760v1)** | 2025-10-29 |  |
| **[SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning](http://arxiv.org/abs/2506.21355v2)** | 2025-10-29 | <details><summary>NeurI...</summary><p>NeurIPS 2025 (Datasets & Benchmarks Track)</p></details> |
| **[RLAIF-V: Open-Source AI Feedback Leads to Super GPT-4V Trustworthiness](http://arxiv.org/abs/2405.17220v3)** | 2025-10-29 | <details><summary>Proje...</summary><p>Project Website: https://github.com/RLHF-V/RLAIF-V</p></details> |
| **[FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual Question Answering](http://arxiv.org/abs/2506.21710v2)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025 - main track. Project page: https://focus-mllm-vqa.github.io/</p></details> |
| **[RoboOmni: Proactive Robot Manipulation in Omni-modal Context](http://arxiv.org/abs/2510.23763v2)** | 2025-10-29 |  |
| **[Open3D-VQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space](http://arxiv.org/abs/2503.11094v3)** | 2025-10-29 |  |
| **[HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models](http://arxiv.org/abs/2510.20322v2)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted by NeurIPS2025 (Oral)</p></details> |
| **[LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation](http://arxiv.org/abs/2510.25263v1)** | 2025-10-29 | <details><summary>10 pa...</summary><p>10 pages, 5 figures, 14 tables, Neurips 2025</p></details> |
| **[NoisyGRPO: Incentivizing Multimodal CoT Reasoning via Noise Injection and Bayesian Estimation](http://arxiv.org/abs/2510.21122v2)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted by Neurips2025, Project page at at https://artanic30.github.io/project_pages/NoisyGRPO/</p></details> |
| **[InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts](http://arxiv.org/abs/2505.19028v4)** | 2025-10-29 |  |
| **[FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning](http://arxiv.org/abs/2510.24980v1)** | 2025-10-28 |  |
| **[MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness](http://arxiv.org/abs/2505.20426v3)** | 2025-10-28 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025 DB Track</p></details> |
| **[Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs](http://arxiv.org/abs/2510.24514v1)** | 2025-10-28 |  |
| **[SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing](http://arxiv.org/abs/2510.24820v1)** | 2025-10-28 |  |
| **[PANDA: Towards Generalist Video Anomaly Detection via Agentic AI Engineer](http://arxiv.org/abs/2509.26386v2)** | 2025-10-28 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions](http://arxiv.org/abs/2505.21724v2)** | 2025-10-28 | 25 pages, 9 figures |
| **[SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space](http://arxiv.org/abs/2510.24446v1)** | 2025-10-28 |  |
| **[Perception, Understanding and Reasoning, A Multimodal Benchmark for Video Fake News Detection](http://arxiv.org/abs/2510.24816v1)** | 2025-10-28 |  |
| **[SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs](http://arxiv.org/abs/2510.24214v1)** | 2025-10-28 | NeurIPS 2025 |
| **[MGA: Memory-Driven GUI Agent for Observation-Centric Interaction](http://arxiv.org/abs/2510.24168v1)** | 2025-10-28 | Submitted to WWW2025 |

