---
title: Latest 20 Papers - November 11, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## AND:multimodal LLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards](http://arxiv.org/abs/2511.07403v1)** | 2025-11-10 | <details><summary>Prepr...</summary><p>Preprint. Accepted at NeurIPS 2025 Workshops on SPACE in Vision, Language, and Embodied AI (SpaVLE), Embodied World Models for Decision Making (EWM), Aligning Reinforcement Learning Experimentalists and Theorists (ARLET), and Scaling Environments for Agents (SEA)</p></details> |
| **[Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction](http://arxiv.org/abs/2511.07392v1)** | 2025-11-10 | <details><summary>22 pa...</summary><p>22 pages, 12 figures, 1 table, Supplementary Information, Supplementary Data 1</p></details> |
| **[Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large Language Models](http://arxiv.org/abs/2511.07253v1)** | 2025-11-10 | <details><summary>Proje...</summary><p>Project website: https://umbertocappellazzo.github.io/Omni-AVSR/</p></details> |
| **[MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs](http://arxiv.org/abs/2511.07250v1)** | 2025-11-10 |  |
| **[CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation](http://arxiv.org/abs/2510.19670v2)** | 2025-11-10 | 19 pages,8 figures |
| **[Wasm: A Pipeline for Constructing Structured Arabic Interleaved Multimodal Corpora](http://arxiv.org/abs/2511.07080v1)** | 2025-11-10 |  |
| **[Multi-Agent AI Framework for Road Situation Detection and C-ITS Message Generation](http://arxiv.org/abs/2511.06892v1)** | 2025-11-10 | <details><summary>submi...</summary><p>submitted to TRA 2026</p></details> |
| **[LLMCARE: early detection of cognitive impairment via transformer models enhanced by LLM-generated synthetic data](http://arxiv.org/abs/2508.10027v3)** | 2025-11-10 |  |
| **[PanoNav: Mapless Zero-Shot Object Navigation with Panoramic Scene Parsing and Dynamic Memory](http://arxiv.org/abs/2511.06840v1)** | 2025-11-10 | <details><summary>Accep...</summary><p>Accepted as a poster in AAAI 2026</p></details> |
| **[MERaLiON-SER: Robust Speech Emotion Recognition Model for English and SEA Languages](http://arxiv.org/abs/2511.04914v2)** | 2025-11-10 | <details><summary>https...</summary><p>https://huggingface.co/MERaLiON/MERaLiON-SER-v1</p></details> |
| **[Towards Visual Grounding: A Survey](http://arxiv.org/abs/2412.20206v2)** | 2025-11-10 | <details><summary>Accep...</summary><p>Accepted by TPAMI 2025.We keep tracing related works at https://github.com/linhuixiao/Awesome-Visual-Grounding</p></details> |
| **[PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning on Scientific Literature](http://arxiv.org/abs/2510.10909v3)** | 2025-11-10 | 12 pages, 9 figures |
| **[DIFFA: Large Language Diffusion Models Can Listen and Understand](http://arxiv.org/abs/2507.18452v3)** | 2025-11-10 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[Towards Resource-Efficient Multimodal Intelligence: Learned Routing among Specialized Expert Models](http://arxiv.org/abs/2511.06441v1)** | 2025-11-09 | 15 pages, 4 figures |
| **[TimeSense:Making Large Language Models Proficient in Time-Series Analysis](http://arxiv.org/abs/2511.06344v1)** | 2025-11-09 |  |
| **[ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support Issues?](http://arxiv.org/abs/2507.05639v2)** | 2025-11-09 | <details><summary>Accep...</summary><p>Accepted as a main conference paper at EMNLP 2025</p></details> |
| **[SkinCaRe: A Multimodal Dermatology Dataset Annotated with Medical Caption and Chain-of-Thought Reasoning](http://arxiv.org/abs/2405.18004v2)** | 2025-11-09 |  |
| **[Auditing M-LLMs for Privacy Risks: A Synthetic Benchmark and Evaluation Framework](http://arxiv.org/abs/2511.03248v2)** | 2025-11-09 | <details><summary>14 pa...</summary><p>14 pages, 3 figures; Accepted by MMM 2026; Complete version in progress. Dataset available at https://huggingface.co/datasets/xaddh/multimodal-privacy</p></details> |
| **[VideoCAD: A Dataset and Model for Learning Long-Horizon 3D CAD UI Interactions from Video](http://arxiv.org/abs/2505.24838v2)** | 2025-11-08 |  |
| **[Towards Human-AI-Robot Collaboration and AI-Agent based Digital Twins for Parkinson's Disease Management: Review and Outlook](http://arxiv.org/abs/2511.06036v1)** | 2025-11-08 | <details><summary>20 pa...</summary><p>20 pages, 5 figures, 4 tables, under review with a journal</p></details> |

## AND:multimodal survey
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data](http://arxiv.org/abs/2511.06943v1)** | 2025-11-10 | <details><summary>Prepr...</summary><p>Preprint version of the paper accepted at the 40th AAAI Conference on Artificial Intelligence (AAAI-26), organized by the Association for the Advancement of Artificial Intelligence</p></details> |
| **[Towards Visual Grounding: A Survey](http://arxiv.org/abs/2412.20206v2)** | 2025-11-10 | <details><summary>Accep...</summary><p>Accepted by TPAMI 2025.We keep tracing related works at https://github.com/linhuixiao/Awesome-Visual-Grounding</p></details> |
| **[Cognitive Edge Computing: A Comprehensive Survey on Optimizing Large Models and AI Agents for Pervasive Deployment](http://arxiv.org/abs/2501.03265v2)** | 2025-11-07 |  |
| **[Graph Learning](http://arxiv.org/abs/2507.05636v2)** | 2025-11-07 | 185 pages |
| **[RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods](http://arxiv.org/abs/2511.03939v1)** | 2025-11-06 |  |
| **[Reinforcement Learning Foundations for Deep Research Systems: A Survey](http://arxiv.org/abs/2509.06733v2)** | 2025-11-05 | <details><summary>39 pa...</summary><p>39 pages, second version</p></details> |
| **[Prevailing Research Areas for Music AI in the Era of Foundation Models](http://arxiv.org/abs/2409.09378v3)** | 2025-11-04 |  |
| **[Machine Olfaction and Embedded AI Are Shaping the New Global Sensing Industry](http://arxiv.org/abs/2510.19660v2)** | 2025-11-03 | <details><summary>23 pa...</summary><p>23 pages, 116 citations, combination tech review/industry roadmap/white paper on the rise of machine olfaction as an essential AI modality</p></details> |
| **[A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models](http://arxiv.org/abs/2509.11575v2)** | 2025-11-02 | <details><summary>This ...</summary><p>This paper is currently under review</p></details> |
| **[Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](http://arxiv.org/abs/2510.25760v2)** | 2025-11-02 |  |
| **[A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation](http://arxiv.org/abs/2510.19755v3)** | 2025-11-01 | 22 pages,2 figures |
| **[All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles](http://arxiv.org/abs/2510.26641v1)** | 2025-10-30 |  |
| **[Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models](http://arxiv.org/abs/2510.05034v5)** | 2025-10-28 | Version v1.1 |
| **[Toward Socially-Aware LLMs: A Survey of Multimodal Approaches to Human Behavior Understanding](http://arxiv.org/abs/2510.23947v1)** | 2025-10-28 |  |
| **[LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell Biology](http://arxiv.org/abs/2510.07793v2)** | 2025-10-27 | <details><summary>34 pa...</summary><p>34 pages, 5 figures, 7 tables</p></details> |
| **[Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges](http://arxiv.org/abs/2510.22964v1)** | 2025-10-27 |  |
| **[A Survey of Long-Document Retrieval in the PLM and LLM Era](http://arxiv.org/abs/2509.07759v2)** | 2025-10-25 | 32 pages, 6 figures |
| **[Bridging the Perceptual-Statistical Gap in Dysarthria Assessment: Why Machine Learning Still Falls Short](http://arxiv.org/abs/2510.22237v1)** | 2025-10-25 |  |
| **[Deep Literature Survey Automation with an Iterative Workflow](http://arxiv.org/abs/2510.21900v1)** | 2025-10-24 | Preprint version |
| **[Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques](http://arxiv.org/abs/2410.18972v2)** | 2025-10-24 |  |

## AND:MLLM post training
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View](http://arxiv.org/abs/2511.06722v1)** | 2025-11-10 | <details><summary>Accpe...</summary><p>Accpeted by AAAI 2026</p></details> |
| **[Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback](http://arxiv.org/abs/2510.16888v3)** | 2025-11-04 |  |
| **[SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning](http://arxiv.org/abs/2511.02280v1)** | 2025-11-04 |  |
| **[Learning to Steer: Input-dependent Steering for Multimodal LLMs](http://arxiv.org/abs/2508.12815v2)** | 2025-11-02 | NeurIPS 2025 |
| **[Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](http://arxiv.org/abs/2510.25760v2)** | 2025-11-02 |  |
| **[Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond](http://arxiv.org/abs/2511.00389v1)** | 2025-11-01 |  |
| **[SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing](http://arxiv.org/abs/2510.24820v1)** | 2025-10-28 |  |
| **[First SFT, Second RL, Third UPT: Continual Improving Multi-Modal LLM Reasoning via Unsupervised Post-Training](http://arxiv.org/abs/2505.22453v2)** | 2025-10-27 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[LUQ: Layerwise Ultra-Low Bit Quantization for Multimodal Large Language Models](http://arxiv.org/abs/2509.23729v2)** | 2025-10-26 |  |
| **[Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](http://arxiv.org/abs/2508.05612v3)** | 2025-10-21 | <details><summary>Proje...</summary><p>Project page at: https://xenozlh.github.io/Shuffle-R1/</p></details> |
| **[GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image](http://arxiv.org/abs/2510.17157v1)** | 2025-10-20 |  |
| **[Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence](http://arxiv.org/abs/2510.16555v1)** | 2025-10-18 |  |
| **[REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting](http://arxiv.org/abs/2510.16410v1)** | 2025-10-18 |  |
| **[RL makes MLLMs see better than SFT](http://arxiv.org/abs/2510.16333v1)** | 2025-10-18 |  |
| **[Detect Anything via Next Point Prediction](http://arxiv.org/abs/2510.12798v1)** | 2025-10-14 | <details><summary>homep...</summary><p>homepage: https://rex-omni.github.io/</p></details> |
| **[MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization](http://arxiv.org/abs/2510.08540v2)** | 2025-10-11 |  |
| **[RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models](http://arxiv.org/abs/2506.18369v4)** | 2025-10-10 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025</p></details> |
| **[Play to Generalize: Learning to Reason Through Game Play](http://arxiv.org/abs/2506.08011v4)** | 2025-10-09 | <details><summary>Proje...</summary><p>Project Page: https://yunfeixie233.github.io/ViGaL/</p></details> |
| **[PiCo: Jailbreaking Multimodal Large Language Models via Pictorial Code Contextualization](http://arxiv.org/abs/2504.01444v4)** | 2025-10-09 | <details><summary>Accep...</summary><p>Accepted to IEEE International Conference on Multimedia and Expo (ICME) 2025</p></details> |
| **[ReLoop: "Seeing Twice and Thinking Backwards" via Closed-loop Training to Mitigate Hallucinations in Multimodal understanding](http://arxiv.org/abs/2507.04943v2)** | 2025-09-30 | <details><summary>Accep...</summary><p>Accepted by conference EMNLP2025</p></details> |

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards](http://arxiv.org/abs/2511.07403v1)** | 2025-11-10 | <details><summary>Prepr...</summary><p>Preprint. Accepted at NeurIPS 2025 Workshops on SPACE in Vision, Language, and Embodied AI (SpaVLE), Embodied World Models for Decision Making (EWM), Aligning Reinforcement Learning Experimentalists and Theorists (ARLET), and Scaling Environments for Agents (SEA)</p></details> |
| **[MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs](http://arxiv.org/abs/2511.07250v1)** | 2025-11-10 |  |
| **[From Pretrain to Pain: Adversarial Vulnerability of Video Foundation Models Without Task Knowledge](http://arxiv.org/abs/2511.07049v1)** | 2025-11-10 | <details><summary>AAAI ...</summary><p>AAAI 2026 (Oral presentation)</p></details> |
| **[Multi-Agent AI Framework for Road Situation Detection and C-ITS Message Generation](http://arxiv.org/abs/2511.06892v1)** | 2025-11-10 | <details><summary>submi...</summary><p>submitted to TRA 2026</p></details> |
| **[HydraInfer: Hybrid Disaggregated Scheduling for Multimodal Large Language Model Serving](http://arxiv.org/abs/2505.12658v2)** | 2025-11-10 |  |
| **[PanoNav: Mapless Zero-Shot Object Navigation with Panoramic Scene Parsing and Dynamic Memory](http://arxiv.org/abs/2511.06840v1)** | 2025-11-10 | <details><summary>Accep...</summary><p>Accepted as a poster in AAAI 2026</p></details> |
| **[MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning](http://arxiv.org/abs/2511.06805v1)** | 2025-11-10 | 19 pages, 11 figures |
| **[Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models](http://arxiv.org/abs/2511.06793v1)** | 2025-11-10 | <details><summary>Accep...</summary><p>Accepted at AAAI 2026 as a Conference Paper (Oral Presentation)</p></details> |
| **[Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View](http://arxiv.org/abs/2511.06722v1)** | 2025-11-10 | <details><summary>Accpe...</summary><p>Accpeted by AAAI 2026</p></details> |
| **[FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis](http://arxiv.org/abs/2511.06522v1)** | 2025-11-09 | <details><summary>Accep...</summary><p>Accepted to The 5th Workshop on Mathematical Reasoning and AI at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025); 25 pages, 14 figures, 8 tables; Code available at https://github.com/NaiveNeuron/FractalBench</p></details> |
| **[SportR: A Benchmark for Multimodal Large Language Model Reasoning in Sports](http://arxiv.org/abs/2511.06499v1)** | 2025-11-09 |  |
| **[AUTO-Explorer: Automated Data Collection for GUI Agent](http://arxiv.org/abs/2511.06417v1)** | 2025-11-09 |  |
| **[InfoAffect: A Dataset for Affective Analysis of Infographics](http://arxiv.org/abs/2511.06404v1)** | 2025-11-09 |  |
| **[AesTest: Measuring Aesthetic Intelligence from Perception to Production](http://arxiv.org/abs/2511.06360v1)** | 2025-11-09 | 10 pages, 9 figures |
| **[VideoSSR: Video Self-Supervised Reinforcement Learning](http://arxiv.org/abs/2511.06281v1)** | 2025-11-09 |  |
| **[VLDrive: Vision-Augmented Lightweight MLLMs for Efficient Language-grounded Autonomous Driving](http://arxiv.org/abs/2511.06256v1)** | 2025-11-09 | Accepted by ICCV2025 |
| **[Auditing M-LLMs for Privacy Risks: A Synthetic Benchmark and Evaluation Framework](http://arxiv.org/abs/2511.03248v2)** | 2025-11-09 | <details><summary>14 pa...</summary><p>14 pages, 3 figures; Accepted by MMM 2026; Complete version in progress. Dataset available at https://huggingface.co/datasets/xaddh/multimodal-privacy</p></details> |
| **[MLLM-For3D: Adapting Multimodal Large Language Model for 3D Reasoning Segmentation](http://arxiv.org/abs/2503.18135v2)** | 2025-11-08 | 10 pages, 3 figures |
| **[FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian Scene without Spatial Priors](http://arxiv.org/abs/2505.01322v4)** | 2025-11-08 | <details><summary>Accep...</summary><p>Accepted by ACMMM2025, Our project webpage: https://tjulcx.github.io/FreeInsert/</p></details> |
| **[A Remarkably Efficient Paradigm to Multimodal Large Language Models for Sequential Recommendation](http://arxiv.org/abs/2511.05885v1)** | 2025-11-08 |  |

