---
title: Latest 20 Papers - November 05, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## AND:multimodal LLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding](http://arxiv.org/abs/2410.22211v2)** | 2025-11-04 | <details><summary>NAACL...</summary><p>NAACL2025, Code and Data: https://github.com/kimihiroh/promqa</p></details> |
| **[Can Visual Input Be Compressed? A Visual Token Compression Benchmark for Large Multimodal Models](http://arxiv.org/abs/2511.02650v1)** | 2025-11-04 |  |
| **[A Tutorial on Cognitive Biases in Agentic AI-Driven 6G Autonomous Networks](http://arxiv.org/abs/2510.19973v2)** | 2025-11-04 | <details><summary>19 pa...</summary><p>19 pages, 15 figures, 1 table, link to source code available</p></details> |
| **[Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation](http://arxiv.org/abs/2511.02358v1)** | 2025-11-04 | <details><summary>Accep...</summary><p>Accepted to MMGenSR Workshop (CIKM 2025)</p></details> |
| **[Language-Enhanced Generative Modeling for PET Synthesis from MRI and Blood Biomarkers](http://arxiv.org/abs/2511.02206v1)** | 2025-11-04 | 31 pages, 8 figures |
| **[DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning](http://arxiv.org/abs/2505.20241v3)** | 2025-11-04 | <details><summary>28 pa...</summary><p>28 pages, 10 figures, to appear in NeurIPS 2025 (Conference on Neural Information Processing Systems)</p></details> |
| **[Forging Time Series with Language: A Large Language Model Approach to Synthetic Data Generation](http://arxiv.org/abs/2505.17103v2)** | 2025-11-03 |  |
| **[SemBench: A Benchmark for Semantic Query Processing Engines](http://arxiv.org/abs/2511.01716v1)** | 2025-11-03 |  |
| **[Automate Strategy Finding with LLM in Quant Investment](http://arxiv.org/abs/2409.06289v4)** | 2025-11-03 |  |
| **[SeaLLMs-Audio: Large Audio-Language Models for Southeast Asia](http://arxiv.org/abs/2511.01670v1)** | 2025-11-03 | 10 pages |
| **[Analyzing Sustainability Messaging in Large-Scale Corporate Social Media](http://arxiv.org/abs/2511.01550v1)** | 2025-11-03 |  |
| **[From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems](http://arxiv.org/abs/2505.15685v2)** | 2025-11-03 | <details><summary>EMNLP...</summary><p>EMNLP 2025 camera ready</p></details> |
| **[MotionGPT3: Human Motion as a Second Modality](http://arxiv.org/abs/2506.24086v3)** | 2025-11-03 | 26 pages, 11 figures |
| **[Learning to Steer: Input-dependent Steering for Multimodal LLMs](http://arxiv.org/abs/2508.12815v2)** | 2025-11-02 | NeurIPS 2025 |
| **[A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models](http://arxiv.org/abs/2509.11575v2)** | 2025-11-02 | <details><summary>This ...</summary><p>This paper is currently under review</p></details> |
| **[BiMediX2: Bio-Medical EXpert LMM for Diverse Medical Modalities](http://arxiv.org/abs/2412.07769v2)** | 2025-11-02 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 (Findings)</p></details> |
| **[Fleming-VL: Towards Universal Medical Visual Reasoning with Multimodal LLMs](http://arxiv.org/abs/2511.00916v1)** | 2025-11-02 |  |
| **[Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs](http://arxiv.org/abs/2510.22603v2)** | 2025-11-02 | <details><summary>The c...</summary><p>The code is available at https://github.com/umbertocappellazzo/Llama-AVSR</p></details> |
| **[AlignVLM: Bridging Vision and Language Latent Spaces for Multimodal Document Understanding](http://arxiv.org/abs/2502.01341v2)** | 2025-11-02 |  |
| **[FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs](http://arxiv.org/abs/2509.16648v3)** | 2025-11-02 | <details><summary>Accep...</summary><p>Accepted in the Findings of EMNLP, 2025</p></details> |

## AND:multimodal survey
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Prevailing Research Areas for Music AI in the Era of Foundation Models](http://arxiv.org/abs/2409.09378v3)** | 2025-11-04 |  |
| **[Machine Olfaction and Embedded AI Are Shaping the New Global Sensing Industry](http://arxiv.org/abs/2510.19660v2)** | 2025-11-03 | <details><summary>23 pa...</summary><p>23 pages, 116 citations, combination tech review/industry roadmap/white paper on the rise of machine olfaction as an essential AI modality</p></details> |
| **[A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models](http://arxiv.org/abs/2509.11575v2)** | 2025-11-02 | <details><summary>This ...</summary><p>This paper is currently under review</p></details> |
| **[Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](http://arxiv.org/abs/2510.25760v2)** | 2025-11-02 |  |
| **[A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation](http://arxiv.org/abs/2510.19755v3)** | 2025-11-01 | 22 pages,2 figures |
| **[All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles](http://arxiv.org/abs/2510.26641v1)** | 2025-10-30 |  |
| **[Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models](http://arxiv.org/abs/2510.05034v5)** | 2025-10-28 | Version v1.1 |
| **[Toward Socially-Aware LLMs: A Survey of Multimodal Approaches to Human Behavior Understanding](http://arxiv.org/abs/2510.23947v1)** | 2025-10-28 |  |
| **[LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell Biology](http://arxiv.org/abs/2510.07793v2)** | 2025-10-27 | <details><summary>34 pa...</summary><p>34 pages, 5 figures, 7 tables</p></details> |
| **[Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges](http://arxiv.org/abs/2510.22964v1)** | 2025-10-27 |  |
| **[A Survey of Long-Document Retrieval in the PLM and LLM Era](http://arxiv.org/abs/2509.07759v2)** | 2025-10-25 | 32 pages, 6 figures |
| **[Bridging the Perceptual-Statistical Gap in Dysarthria Assessment: Why Machine Learning Still Falls Short](http://arxiv.org/abs/2510.22237v1)** | 2025-10-25 |  |
| **[Deep Literature Survey Automation with an Iterative Workflow](http://arxiv.org/abs/2510.21900v1)** | 2025-10-24 | Preprint version |
| **[Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques](http://arxiv.org/abs/2410.18972v2)** | 2025-10-24 |  |
| **[LLM-empowered knowledge graph construction: A survey](http://arxiv.org/abs/2510.20345v1)** | 2025-10-23 |  |
| **[Review of Tools for Zero-Code LLM Based Application Development](http://arxiv.org/abs/2510.19747v1)** | 2025-10-22 | <details><summary>Accep...</summary><p>Accepted in 6th World Conference on Artificial Intelligence: Advances and Applications (WCAIAA 2025)</p></details> |
| **[A Survey of Process Reward Models: From Outcome Signals to Process Supervisions for Large Language Models](http://arxiv.org/abs/2510.08049v2)** | 2025-10-21 |  |
| **[DeepSeek-Inspired Exploration of RL-based LLMs and Synergy with Wireless Networks: A Survey](http://arxiv.org/abs/2503.09956v4)** | 2025-10-20 | 45 pages, 12 figures |
| **[From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery](http://arxiv.org/abs/2508.14111v2)** | 2025-10-20 |  |
| **[From Multimodal Perception to Strategic Reasoning: A Survey on AI-Generated Game Commentary](http://arxiv.org/abs/2506.17294v2)** | 2025-10-18 |  |

## AND:MLLM post training
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback](http://arxiv.org/abs/2510.16888v3)** | 2025-11-04 |  |
| **[SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning](http://arxiv.org/abs/2511.02280v1)** | 2025-11-04 |  |
| **[Learning to Steer: Input-dependent Steering for Multimodal LLMs](http://arxiv.org/abs/2508.12815v2)** | 2025-11-02 | NeurIPS 2025 |
| **[Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks](http://arxiv.org/abs/2510.25760v2)** | 2025-11-02 |  |
| **[Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond](http://arxiv.org/abs/2511.00389v1)** | 2025-11-01 |  |
| **[SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing](http://arxiv.org/abs/2510.24820v1)** | 2025-10-28 |  |
| **[First SFT, Second RL, Third UPT: Continual Improving Multi-Modal LLM Reasoning via Unsupervised Post-Training](http://arxiv.org/abs/2505.22453v2)** | 2025-10-27 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[LUQ: Layerwise Ultra-Low Bit Quantization for Multimodal Large Language Models](http://arxiv.org/abs/2509.23729v2)** | 2025-10-26 |  |
| **[Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](http://arxiv.org/abs/2508.05612v3)** | 2025-10-21 | <details><summary>Proje...</summary><p>Project page at: https://xenozlh.github.io/Shuffle-R1/</p></details> |
| **[GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image](http://arxiv.org/abs/2510.17157v1)** | 2025-10-20 |  |
| **[Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence](http://arxiv.org/abs/2510.16555v1)** | 2025-10-18 |  |
| **[REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting](http://arxiv.org/abs/2510.16410v1)** | 2025-10-18 |  |
| **[RL makes MLLMs see better than SFT](http://arxiv.org/abs/2510.16333v1)** | 2025-10-18 |  |
| **[Detect Anything via Next Point Prediction](http://arxiv.org/abs/2510.12798v1)** | 2025-10-14 | <details><summary>homep...</summary><p>homepage: https://rex-omni.github.io/</p></details> |
| **[MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization](http://arxiv.org/abs/2510.08540v2)** | 2025-10-11 |  |
| **[RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models](http://arxiv.org/abs/2506.18369v4)** | 2025-10-10 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025</p></details> |
| **[Play to Generalize: Learning to Reason Through Game Play](http://arxiv.org/abs/2506.08011v4)** | 2025-10-09 | <details><summary>Proje...</summary><p>Project Page: https://yunfeixie233.github.io/ViGaL/</p></details> |
| **[PiCo: Jailbreaking Multimodal Large Language Models via Pictorial Code Contextualization](http://arxiv.org/abs/2504.01444v4)** | 2025-10-09 | <details><summary>Accep...</summary><p>Accepted to IEEE International Conference on Multimedia and Expo (ICME) 2025</p></details> |
| **[ReLoop: "Seeing Twice and Thinking Backwards" via Closed-loop Training to Mitigate Hallucinations in Multimodal understanding](http://arxiv.org/abs/2507.04943v2)** | 2025-09-30 | <details><summary>Accep...</summary><p>Accepted by conference EMNLP2025</p></details> |
| **[LFTR: Learning-Free Token Reduction for Multimodal Large Language Models](http://arxiv.org/abs/2501.17391v3)** | 2025-09-30 |  |

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for Understanding Anything](http://arxiv.org/abs/2511.02834v1)** | 2025-11-04 | <details><summary>16 pa...</summary><p>16 pages, 7 figures, 14 tables. Under Review</p></details> |
| **[When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning](http://arxiv.org/abs/2511.02794v1)** | 2025-11-04 | <details><summary>Accep...</summary><p>Accepted at the Multimodal Algorithmic Reasoning (MAR) Workshop, NeurIPS 2025</p></details> |
| **[UniChange: Unifying Change Detection with Multimodal Large Language Model](http://arxiv.org/abs/2511.02607v1)** | 2025-11-04 |  |
| **[Can MLLMs Read the Room? A Multimodal Benchmark for Verifying Truthfulness in Multi-Party Social Interactions](http://arxiv.org/abs/2510.27195v2)** | 2025-11-04 | ICCV2025 Workshop |
| **[Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback](http://arxiv.org/abs/2510.16888v3)** | 2025-11-04 |  |
| **[OmniEarth-Bench: Towards Holistic Evaluation of Earth's Six Spheres and Cross-Spheres Interactions with Multimodal Observational Earth Data](http://arxiv.org/abs/2505.23522v2)** | 2025-11-04 |  |
| **[ChartM$^3$: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension](http://arxiv.org/abs/2511.02415v1)** | 2025-11-04 | <details><summary>23 pa...</summary><p>23 pages, EMNLP25 Accepted</p></details> |
| **[Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation](http://arxiv.org/abs/2511.02358v1)** | 2025-11-04 | <details><summary>Accep...</summary><p>Accepted to MMGenSR Workshop (CIKM 2025)</p></details> |
| **[InternSVG: Towards Unified SVG Tasks with Multimodal Large Language Models](http://arxiv.org/abs/2510.11341v2)** | 2025-11-04 |  |
| **[SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning](http://arxiv.org/abs/2511.02280v1)** | 2025-11-04 |  |
| **[When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs](http://arxiv.org/abs/2511.02243v1)** | 2025-11-04 | 19 pages |
| **[An Evaluation of Interleaved Instruction Tuning on Semantic Reasoning Performance in an Audio MLLM](http://arxiv.org/abs/2511.02234v1)** | 2025-11-04 |  |
| **[DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning](http://arxiv.org/abs/2505.20241v3)** | 2025-11-04 | <details><summary>28 pa...</summary><p>28 pages, 10 figures, to appear in NeurIPS 2025 (Conference on Neural Information Processing Systems)</p></details> |
| **[TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning](http://arxiv.org/abs/2511.01833v1)** | 2025-11-03 | Preprint |
| **[Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos](http://arxiv.org/abs/2501.04001v3)** | 2025-11-03 | <details><summary>Code:...</summary><p>Code: https://github.com/Bytedance/Sa2VA</p></details> |
| **[ShortV: Efficient Multimodal Large Language Models by Freezing Visual Tokens in Ineffective Layers](http://arxiv.org/abs/2504.00502v2)** | 2025-11-03 | <details><summary>Publi...</summary><p>Published as a conference paper at ICCV 2025. Project page: https://github.com/icip-cas/ShortV</p></details> |
| **[Enhancing Diffusion-based Restoration Models via Difficulty-Adaptive Reinforcement Learning with IQA Reward](http://arxiv.org/abs/2511.01645v1)** | 2025-11-03 |  |
| **[Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models](http://arxiv.org/abs/2511.01618v1)** | 2025-11-03 |  |
| **[MARS: Multi-Agent Robotic System with Multimodal Large Language Models for Assistive Intelligence](http://arxiv.org/abs/2511.01594v1)** | 2025-11-03 | <details><summary>3 fig...</summary><p>3 figures, 1 table; under review at Multimedia Systems (Springer)</p></details> |
| **[Wave-Particle (Continuous-Discrete) Dualistic Visual Tokenization for Unified Understanding and Generation](http://arxiv.org/abs/2511.01593v1)** | 2025-11-03 |  |

